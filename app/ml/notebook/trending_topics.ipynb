{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending Topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://smt483:SMT483tls@10.0.104.84:27017/smt483\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import regex as re \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>is_post</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>comments_cnt</th>\n",
       "      <th>reactions_cnt</th>\n",
       "      <th>likes_cnt</th>\n",
       "      <th>loves_cnt</th>\n",
       "      <th>haha_cnt</th>\n",
       "      <th>wow_cnt</th>\n",
       "      <th>sad_cnt</th>\n",
       "      <th>angry_cnt</th>\n",
       "      <th>fb_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>621a04ebad77bb735cfe7e47</td>\n",
       "      <td>2479280</td>\n",
       "      <td>1</td>\n",
       "      <td>2479279</td>\n",
       "      <td>1993145654159487_2577085889098791</td>\n",
       "      <td>Who thinks that McDonalds have been giving sma...</td>\n",
       "      <td>2018-01-01 07:02:00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>all_singapore_stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>621a04ebad77bb735cfe7e48</td>\n",
       "      <td>2479281</td>\n",
       "      <td>1</td>\n",
       "      <td>2479279</td>\n",
       "      <td>1993145654159487_2577076995766347</td>\n",
       "      <td>&lt;Reader Contribution by Jason&gt;  If they are al...</td>\n",
       "      <td>2018-01-01 04:48:00</td>\n",
       "      <td>91.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>all_singapore_stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621a04ebad77bb735cfe7e49</td>\n",
       "      <td>2479282</td>\n",
       "      <td>1</td>\n",
       "      <td>2479279</td>\n",
       "      <td>1993145654159487_2577099185764128</td>\n",
       "      <td>Drug smugglers getting smarter?</td>\n",
       "      <td>2018-01-01 03:36:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>all_singapore_stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>621a04ebad77bb735cfe7e4a</td>\n",
       "      <td>2479283</td>\n",
       "      <td>1</td>\n",
       "      <td>2479279</td>\n",
       "      <td>1993145654159487_2577074285766618</td>\n",
       "      <td>&lt;Reader Contribution by BM&gt;  Parking cibai to ...</td>\n",
       "      <td>2018-01-01 02:39:48</td>\n",
       "      <td>91.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>all_singapore_stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>621a04ebad77bb735cfe7e4b</td>\n",
       "      <td>2479284</td>\n",
       "      <td>1</td>\n",
       "      <td>2479279</td>\n",
       "      <td>1993145654159487_2577071535766893</td>\n",
       "      <td>Simi sai also become SG200? :D :D :D</td>\n",
       "      <td>2018-01-01 02:34:29</td>\n",
       "      <td>34.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>all_singapore_stuff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id       id  is_post parent_id  \\\n",
       "0  621a04ebad77bb735cfe7e47  2479280        1   2479279   \n",
       "1  621a04ebad77bb735cfe7e48  2479281        1   2479279   \n",
       "2  621a04ebad77bb735cfe7e49  2479282        1   2479279   \n",
       "3  621a04ebad77bb735cfe7e4a  2479283        1   2479279   \n",
       "4  621a04ebad77bb735cfe7e4b  2479284        1   2479279   \n",
       "\n",
       "                           object_id  \\\n",
       "0  1993145654159487_2577085889098791   \n",
       "1  1993145654159487_2577076995766347   \n",
       "2  1993145654159487_2577099185764128   \n",
       "3  1993145654159487_2577074285766618   \n",
       "4  1993145654159487_2577071535766893   \n",
       "\n",
       "                                             message        created_time  \\\n",
       "0  Who thinks that McDonalds have been giving sma... 2018-01-01 07:02:00   \n",
       "1  <Reader Contribution by Jason>  If they are al... 2018-01-01 04:48:00   \n",
       "2                    Drug smugglers getting smarter? 2018-01-01 03:36:07   \n",
       "3  <Reader Contribution by BM>  Parking cibai to ... 2018-01-01 02:39:48   \n",
       "4               Simi sai also become SG200? :D :D :D 2018-01-01 02:34:29   \n",
       "\n",
       "   comments_cnt  reactions_cnt  likes_cnt  loves_cnt  haha_cnt  wow_cnt  \\\n",
       "0          86.0          260.0      129.0        3.0      99.0     22.0   \n",
       "1          91.0          211.0      127.0        9.0      60.0      8.0   \n",
       "2           1.0           15.0       10.0        0.0       0.0      4.0   \n",
       "3          91.0          287.0      136.0        6.0     108.0     15.0   \n",
       "4          34.0          113.0       46.0        2.0      46.0      3.0   \n",
       "\n",
       "   sad_cnt  angry_cnt             fb_group  \n",
       "0      2.0        5.0  all_singapore_stuff  \n",
       "1      2.0        5.0  all_singapore_stuff  \n",
       "2      0.0        1.0  all_singapore_stuff  \n",
       "3      1.0       21.0  all_singapore_stuff  \n",
       "4      1.0       15.0  all_singapore_stuff  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_posts = client.smt483.fb_posts\n",
    "fb_posts_df = pd.DataFrame(list(fb_posts.find()))\n",
    "fb_posts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(directory_path: str, file_extension: str) -> list:\n",
    "    \"\"\"\n",
    "    Takes in a filepath and file extension type and returns a list of file names in the same directory.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The base path to folder directory containing all data files\n",
    "        file_extension (str): The file extension type, e.g. (txt, json, csv).\n",
    "\n",
    "    Returns:\n",
    "        list: List of filenames with given extension type.\n",
    "    \"\"\"\n",
    "    file_list = []\n",
    "    for file in glob.glob(f\"{directory_path}/*.{file_extension}\"):\n",
    "        # file_list.append(file)\n",
    "        file_list.append(os.path.relpath(file, os.getcwd()))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_filenames_to_df(filenames: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes in a list of Reddit filenames and converts all text data into a dataframe.\n",
    "\n",
    "    Args:\n",
    "        filenames (list): List of Reddit filenames.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing all texts.\n",
    "    \"\"\"\n",
    "\n",
    "    data_list = []\n",
    "    \n",
    "    for filename in filenames:\n",
    "        file = open(filename)\n",
    "        # if filenames[0][-4:] == 'json':\n",
    "        data = json.load(file)\n",
    "\n",
    "        for post_id in data:\n",
    "            if post_body := data[post_id][\"selftext\"]:\n",
    "                data_list.append(post_body)\n",
    "\n",
    "        # else:\n",
    "        #     json_list = list(file)\n",
    "        #     for json_str in json_list:\n",
    "        #         print(json_str)\n",
    "        #         print(\"/n\")\n",
    "        #         # data = json.loads(json_str)\n",
    "        #         # print(data)\n",
    "        #         # data_list.append(data[\"selftext\"])\n",
    "            \n",
    "    df = pd.DataFrame(data_list, columns=[\"text\"])\n",
    "    df = df.dropna().drop_duplicates(ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "- Remove non-English characters\n",
    "- Remove non-ascii characters\n",
    "- Replace markdown elements\n",
    "- Remove link urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = text.encode('ascii', errors=\"ignore\").decode()\n",
    "    text = \"\".join([ch for ch in text if ch in string.printable])\n",
    "    text = text.replace(\"\\n\", \"\").replace(\"\\nl\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\\\\",\"\").replace(\"--\", \"\").replace(\"|:-\", \"\").replace(\"|\", \" \").replace(\"#\", \"\").replace(\"&x200B;\", \"\")\n",
    "    markdown_removed = re.sub('\\*+\\W+', '', text)\n",
    "    link_removed = re.sub('\\(?https?://[A-Za-z0-9./_\\-!@#$%^&*+={}[\\]<>:;?]*\\)?', '', markdown_removed)\n",
    "\n",
    "    return link_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaned Reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../../raw_data/reddit/daily/2022-02-14.json', '../../../../raw_data/reddit/daily/2022-02-17.json', '../../../../raw_data/reddit/daily/2022-02-19.json', '../../../../raw_data/reddit/daily/2022-02-22.json', '../../../../raw_data/reddit/daily/2022-02-11.json', '../../../../raw_data/reddit/daily/2022-02-18.json', '../../../../raw_data/reddit/daily/2022-02-12.json', '../../../../raw_data/reddit/daily/2022-02-13.json', '../../../../raw_data/reddit/daily/2022-02-24.json', '../../../../raw_data/reddit/daily/2022-02-20.json', '../../../../raw_data/reddit/daily/2022-02-16.json', '../../../../raw_data/reddit/daily/2022-02-15.json', '../../../../raw_data/reddit/daily/2022-02-08.json', '../../../../raw_data/reddit/daily/2022-02-10.json', '../../../../raw_data/reddit/daily/2022-02-21.json', '../../../../raw_data/reddit/daily/2022-02-23.json', '../../../../raw_data/reddit/daily/2022-02-09.json', '../../../../raw_data/reddit/daily/2022-02-25.json']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talk about your day. Anything goes, but subred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># Preface:\\n\\nI moved out at age 15 (though my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basically, you receive one order but before yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was eating at the hawker center last Sunday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As the title says, I am an American coming to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td># Festive Events\\n\\n|DATE|CATEGORY|EVENT|VENUE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Hi, I want to make sure everything goes smooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Today my colleague who just came back from Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>What's an interesting thing which I can only g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>I personally can’t think of one myself, but ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Talk about your day. Anything goes, but subred...\n",
       "1    # Preface:\\n\\nI moved out at age 15 (though my...\n",
       "2    Basically, you receive one order but before yo...\n",
       "3     I was eating at the hawker center last Sunday...\n",
       "4    As the title says, I am an American coming to ...\n",
       "..                                                 ...\n",
       "104  # Festive Events\\n\\n|DATE|CATEGORY|EVENT|VENUE...\n",
       "105  Hi, I want to make sure everything goes smooth...\n",
       "106  Today my colleague who just came back from Ind...\n",
       "107  What's an interesting thing which I can only g...\n",
       "108  I personally can’t think of one myself, but ju...\n",
       "\n",
       "[109 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = get_filenames(\n",
    "    directory_path = \"/home/lingjia/raw_data/reddit/daily\",\n",
    "    file_extension= \"json\"\n",
    ")\n",
    "print(filenames)\n",
    "\n",
    "reddit_data = reddit_filenames_to_df(filenames)\n",
    "reddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talk about your day. Anything goes, but subred...</td>\n",
       "      <td>Talk about your day. Anything goes, but subred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># Preface:\\n\\nI moved out at age 15 (though my...</td>\n",
       "      <td>Preface:I moved out at age 15 (though my pare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basically, you receive one order but before yo...</td>\n",
       "      <td>Basically, you receive one order but before yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was eating at the hawker center last Sunday...</td>\n",
       "      <td>I was eating at the hawker center last Sunday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As the title says, I am an American coming to ...</td>\n",
       "      <td>As the title says, I am an American coming to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td># Festive Events\\n\\n|DATE|CATEGORY|EVENT|VENUE...</td>\n",
       "      <td>Festive Events DATE CATEGORY EVENT VENUE PRIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Hi, I want to make sure everything goes smooth...</td>\n",
       "      <td>Hi, I want to make sure everything goes smooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Today my colleague who just came back from Ind...</td>\n",
       "      <td>Today my colleague who just came back from Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>What's an interesting thing which I can only g...</td>\n",
       "      <td>What's an interesting thing which I can only g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>I personally can’t think of one myself, but ju...</td>\n",
       "      <td>I personally cant think of one myself, but jus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Talk about your day. Anything goes, but subred...   \n",
       "1    # Preface:\\n\\nI moved out at age 15 (though my...   \n",
       "2    Basically, you receive one order but before yo...   \n",
       "3     I was eating at the hawker center last Sunday...   \n",
       "4    As the title says, I am an American coming to ...   \n",
       "..                                                 ...   \n",
       "104  # Festive Events\\n\\n|DATE|CATEGORY|EVENT|VENUE...   \n",
       "105  Hi, I want to make sure everything goes smooth...   \n",
       "106  Today my colleague who just came back from Ind...   \n",
       "107  What's an interesting thing which I can only g...   \n",
       "108  I personally can’t think of one myself, but ju...   \n",
       "\n",
       "                                             cleantext  \n",
       "0    Talk about your day. Anything goes, but subred...  \n",
       "1     Preface:I moved out at age 15 (though my pare...  \n",
       "2    Basically, you receive one order but before yo...  \n",
       "3     I was eating at the hawker center last Sunday...  \n",
       "4    As the title says, I am an American coming to ...  \n",
       "..                                                 ...  \n",
       "104   Festive Events DATE CATEGORY EVENT VENUE PRIC...  \n",
       "105  Hi, I want to make sure everything goes smooth...  \n",
       "106  Today my colleague who just came back from Ind...  \n",
       "107  What's an interesting thing which I can only g...  \n",
       "108  I personally cant think of one myself, but jus...  \n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[\"cleantext\"] = reddit_data[\"text\"].apply(preprocessing)\n",
    "reddit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaned Facebook data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_316891/2394968231.py:1: DtypeWarning: Columns (1,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  facebook_data = pd.read_csv(\"/home/lingjia/raw_data/Facebook/combined_data.csv\", index_col=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Before the days of Internet dating, there was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Man, allegedly high on drugs, tackled by polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\"If it was an accident, fine. But from the vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>This guy really got no chill. Read the full st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>McDonald's Guest Experience Leader, 14, presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433776</th>\n",
       "      <td>JJ Lin will be guest on Christopher Lee's upco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433791</th>\n",
       "      <td>How has your 2021 been? Here's something to he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433804</th>\n",
       "      <td>45 men and four women between the age of 37 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433812</th>\n",
       "      <td>If you don't want to pay S$58 for a chocolate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433822</th>\n",
       "      <td>The students found that filling the cup with 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63156 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  message\n",
       "1       Before the days of Internet dating, there was ...\n",
       "7       Man, allegedly high on drugs, tackled by polic...\n",
       "33      \"If it was an accident, fine. But from the vid...\n",
       "48      This guy really got no chill. Read the full st...\n",
       "94      McDonald's Guest Experience Leader, 14, presen...\n",
       "...                                                   ...\n",
       "433776  JJ Lin will be guest on Christopher Lee's upco...\n",
       "433791  How has your 2021 been? Here's something to he...\n",
       "433804  45 men and four women between the age of 37 an...\n",
       "433812  If you don't want to pay S$58 for a chocolate ...\n",
       "433822  The students found that filling the cup with 5...\n",
       "\n",
       "[63156 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facebook_data = pd.read_csv(\"/home/lingjia/raw_data/Facebook/combined_data.csv\", index_col=0)\n",
    "facebook_posts = facebook_data[facebook_data[\"level\"] == 1][\"message\"]\n",
    "facebook_posts = facebook_posts.to_frame()\n",
    "facebook_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Before the days of Internet dating, there was ...</td>\n",
       "      <td>Before the days of Internet dating, there was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Man, allegedly high on drugs, tackled by polic...</td>\n",
       "      <td>Man, allegedly high on drugs, tackled by polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\"If it was an accident, fine. But from the vid...</td>\n",
       "      <td>\"If it was an accident, fine. But from the vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>This guy really got no chill. Read the full st...</td>\n",
       "      <td>This guy really got no chill. Read the full st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>McDonald's Guest Experience Leader, 14, presen...</td>\n",
       "      <td>McDonald's Guest Experience Leader, 14, presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433776</th>\n",
       "      <td>JJ Lin will be guest on Christopher Lee's upco...</td>\n",
       "      <td>JJ Lin will be guest on Christopher Lee's upco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433791</th>\n",
       "      <td>How has your 2021 been? Here's something to he...</td>\n",
       "      <td>How has your 2021 been? Here's something to he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433804</th>\n",
       "      <td>45 men and four women between the age of 37 an...</td>\n",
       "      <td>45 men and four women between the age of 37 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433812</th>\n",
       "      <td>If you don't want to pay S$58 for a chocolate ...</td>\n",
       "      <td>If you don't want to pay S$58 for a chocolate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433822</th>\n",
       "      <td>The students found that filling the cup with 5...</td>\n",
       "      <td>The students found that filling the cup with 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  message  \\\n",
       "1       Before the days of Internet dating, there was ...   \n",
       "7       Man, allegedly high on drugs, tackled by polic...   \n",
       "33      \"If it was an accident, fine. But from the vid...   \n",
       "48      This guy really got no chill. Read the full st...   \n",
       "94      McDonald's Guest Experience Leader, 14, presen...   \n",
       "...                                                   ...   \n",
       "433776  JJ Lin will be guest on Christopher Lee's upco...   \n",
       "433791  How has your 2021 been? Here's something to he...   \n",
       "433804  45 men and four women between the age of 37 an...   \n",
       "433812  If you don't want to pay S$58 for a chocolate ...   \n",
       "433822  The students found that filling the cup with 5...   \n",
       "\n",
       "                                                cleantext  \n",
       "1       Before the days of Internet dating, there was ...  \n",
       "7       Man, allegedly high on drugs, tackled by polic...  \n",
       "33      \"If it was an accident, fine. But from the vid...  \n",
       "48      This guy really got no chill. Read the full st...  \n",
       "94      McDonald's Guest Experience Leader, 14, presen...  \n",
       "...                                                   ...  \n",
       "433776  JJ Lin will be guest on Christopher Lee's upco...  \n",
       "433791  How has your 2021 been? Here's something to he...  \n",
       "433804  45 men and four women between the age of 37 an...  \n",
       "433812  If you don't want to pay S$58 for a chocolate ...  \n",
       "433822  The students found that filling the cup with 5...  \n",
       "\n",
       "[63156 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facebook_posts[\"cleantext\"] = facebook_posts[\"message\"].apply(preprocessing)\n",
    "facebook_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Matching text with dictionaries for each topic\n",
    "To obtain trending topics, we will be matching each text to dictionaries of different topics. If a proportion of the words exceed a threshold of matching the dictionary, then the text will be tagged to the topic. We set the threshold to 0.7. \n",
    "\n",
    "A text can be tagged to multiple topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(text):\n",
    "    try: \n",
    "        with open('../data/Trending Topics/dictionary/art.csv') as f:\n",
    "            art_dict = set([i for i in f][0].split(\",\"))\n",
    "        with open('../data/Trending Topics/dictionary/covid19.csv') as f:\n",
    "            covid19_dict = set([i for i in f][0].split(\",\"))\n",
    "        with open('../data/Trending Topics/dictionary/education.csv') as f:\n",
    "            edu_dict = set([i for i in f][0].split(\",\"))\n",
    "        with open('../data/Trending Topics/dictionary/environment.csv') as f:\n",
    "            env_dict = set([i for i in f][0].split(\",\"))\n",
    "        with open('../data/Trending Topics/dictionary/fashion.csv') as f:\n",
    "            fashion_dict = set([i for i in f][0].split(\",\"))\n",
    "        with open('../data/Trending Topics/dictionary/food.csv') as f:\n",
    "            food_dict = set([i for i in f][0].split(\",\"))\n",
    "        with open('../data/Trending Topics/dictionary/health.csv') as f:\n",
    "            health_dict = set([i for i in f][0].split(\",\"))\n",
    "        with open('../data/Trending Topics/dictionary/politics.csv') as f:\n",
    "            politics_dict = set([i for i in f][0].split(\",\"))\n",
    "        with open('../data/Trending Topics/dictionary/technology.csv') as f:\n",
    "            tech_dict = set([i for i in f][0].split(\",\"))\n",
    "\n",
    "        topic_dicts = [('art', art_dict), ('covid19', covid19_dict), ('education', edu_dict), ('environment', env_dict), ('fashion', fashion_dict), ('food', food_dict), ('health', health_dict), ('politics', politics_dict), ('technology', tech_dict)]\n",
    "        # print(topic_dicts)\n",
    "\n",
    "        topic_match = {'art':0, 'covid19':0, 'education':0, 'environment':0, 'fashion':0, 'food':0, 'health':0, 'politics':0, 'technology':0}\n",
    "\n",
    "        for i in range(8):\n",
    "            match_text = topic_dicts[i][1].intersection(set(text.split()))\n",
    "            # print(\"MATCHED WORDS\")\n",
    "            # print(topic_dicts[i][0], match_text)\n",
    "\n",
    "            for k in topic_match:\n",
    "                if k == topic_dicts[i][0]:\n",
    "                    topic_match[k] = len(match_text)\n",
    "\n",
    "        return max(topic_match, key=topic_match.get)\n",
    "\n",
    "    except Exception as e:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    lowercase_text = text.lower()\n",
    "    punctuations_removed = re.sub('[^a-z]', ' ', lowercase_text)\n",
    "    tokens = word_tokenize(punctuations_removed)\n",
    "    stopwords_removed = [token for token in tokens if token not in nltk_stopwords]\n",
    "    lemmatized_tokens = [wnl.lemmatize(w) for w in stopwords_removed]    \n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'education'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"No, our education system is doing a pretty good job serving the educational needs of our young while not imposing too much workload or stress on them. This is due to the presence of myriad pathways that students can choose to take. Primary school students can take their subjects at foundation level or at the normal level, secondary school students can choose between 3 or 4 streams, including Express, Normal (A) and Normal (T). Tertiary students can choose between 3 to 4 educational institutions as well. I believe stress does exist but it is not due to the nature of the education system, but due to societal influence, parental/family influence or it is self-imposed by the student.\"\n",
    "\n",
    "cleantext= processing(sentence)\n",
    "get_topics(cleantext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Talk about your day. Anything goes, but subred...</td>\n",
       "      <td>talk day anything go subreddit rule still appl...</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*TL;DR: Because most of the population got vac...</td>\n",
       "      <td>tl dr population got vaccinated covid vaccine ...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The hospital that i go to is struggling to get...</td>\n",
       "      <td>hospital go struggling get therapist ever sinc...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Talk about your day. Anything goes, but subred...   \n",
       "1  *TL;DR: Because most of the population got vac...   \n",
       "2  The hospital that i go to is struggling to get...   \n",
       "\n",
       "                                           cleantext      topic  \n",
       "0  talk day anything go subreddit rule still appl...  education  \n",
       "1  tl dr population got vaccinated covid vaccine ...     health  \n",
       "2  hospital go struggling get therapist ever sinc...   politics  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data[\"cleantext\"] = reddit_data[\"text\"].apply(processing)\n",
    "\n",
    "reddit_data[\"topic\"] = reddit_data[\"cleantext\"].apply(get_topics)\n",
    "reddit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: art\n",
    "2: covid19\n",
    "3: education\n",
    "4: environment\n",
    "5: fashion\n",
    "6: food\n",
    "7: health\n",
    "8: politics\n",
    "9: technology\n",
    "10: others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reddit_data = reddit_data.sample(n=100)\n",
    "sample_reddit_data.to_csv(\"sample_reddit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>5</td>\n",
       "      <td>Thanks for the info. Yes I think I probably do...</td>\n",
       "      <td>thanks info yes think probably use bag time ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>7</td>\n",
       "      <td>Condoms are pretty useful against STDs, which ...</td>\n",
       "      <td>condom pretty useful std appreciate gon na pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>1</td>\n",
       "      <td>What you don't like recycled plots, lifeless c...</td>\n",
       "      <td>like recycled plot lifeless character dialogue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>7</td>\n",
       "      <td>It's &lt;20 in icu, 90+ is needing oxygen support...</td>\n",
       "      <td>icu needing oxygen support nasal prong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31844</th>\n",
       "      <td>1</td>\n",
       "      <td>Never mind then, I guess I was wrong!</td>\n",
       "      <td>never mind guess wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12449</th>\n",
       "      <td>1</td>\n",
       "      <td>Complaint what? He got bigger space than most ...</td>\n",
       "      <td>complaint got bigger space u rent free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25355</th>\n",
       "      <td>1</td>\n",
       "      <td>Trickle down is an urban myth. Gaslighting, re...</td>\n",
       "      <td>trickle urban myth gaslighting really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>6</td>\n",
       "      <td>They are already milking in SGCovidLaKopi</td>\n",
       "      <td>already milking sgcovidlakopi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7684</th>\n",
       "      <td>1</td>\n",
       "      <td>The market can bear the prices they ask, eithe...</td>\n",
       "      <td>market bear price ask either actual quality ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24583</th>\n",
       "      <td>1</td>\n",
       "      <td>how to count my caloriesss when my mom is such...</td>\n",
       "      <td>count calorie mom good cook lmao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>1</td>\n",
       "      <td>If ART negative, pretty safe</td>\n",
       "      <td>art negative pretty safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25259</th>\n",
       "      <td>10</td>\n",
       "      <td>tennis1shoe that bastard stole my girl pingpon...</td>\n",
       "      <td>tennis shoe bastard stole girl pingpong shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25934</th>\n",
       "      <td>1</td>\n",
       "      <td>I want to know what you have been smoking… so ...</td>\n",
       "      <td>want know smoking try jail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10141</th>\n",
       "      <td>5</td>\n",
       "      <td>one of the good result from lockdown</td>\n",
       "      <td>one good result lockdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39111</th>\n",
       "      <td>3</td>\n",
       "      <td>If this were Soviet Russia, they would have fo...</td>\n",
       "      <td>soviet russia would found way operate liberal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20132</th>\n",
       "      <td>3</td>\n",
       "      <td>I saw some tiktok video of this lab worker who...</td>\n",
       "      <td>saw tiktok video lab worker antibody test jab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38113</th>\n",
       "      <td>1</td>\n",
       "      <td>Should have said that it was a workplace event</td>\n",
       "      <td>said workplace event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>5</td>\n",
       "      <td>I heard from somewhere that this is a sign of ...</td>\n",
       "      <td>heard somewhere sign anti social lonely people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36924</th>\n",
       "      <td>1</td>\n",
       "      <td>\\\\[T]/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>5</td>\n",
       "      <td>They put down a 70% deposit with the ID. Yikes...</td>\n",
       "      <td>put deposit id yikes huge red flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38254</th>\n",
       "      <td>1</td>\n",
       "      <td>So that I can collect garbage like u?</td>\n",
       "      <td>collect garbage like u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>5</td>\n",
       "      <td>Any good spots to work from in sg? Staying at ...</td>\n",
       "      <td>good spot work sg staying home day sian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24013</th>\n",
       "      <td>1</td>\n",
       "      <td>We can be anything we wish to be online</td>\n",
       "      <td>anything wish online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt;excessive excellent alternates\\n\\nThesaurus w...</td>\n",
       "      <td>excessive excellent alternate thesaurus workin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19737</th>\n",
       "      <td>3</td>\n",
       "      <td>This doesn't solve the problem\\n\\nIf you read ...</td>\n",
       "      <td>solve problem read ocbc incident part issue du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29666</th>\n",
       "      <td>1</td>\n",
       "      <td>wait till you learn what NTUC meant</td>\n",
       "      <td>wait till learn ntuc meant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20728</th>\n",
       "      <td>5</td>\n",
       "      <td>Pretty nicely endowed for an asian</td>\n",
       "      <td>pretty nicely endowed asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35219</th>\n",
       "      <td>5</td>\n",
       "      <td>Pretty much impossible  \\n\\nIf you're still yo...</td>\n",
       "      <td>pretty much impossible still young need take a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24709</th>\n",
       "      <td>7</td>\n",
       "      <td>You are not responsible his mental health.\\n\\n...</td>\n",
       "      <td>responsible mental health made clear reciproca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17037</th>\n",
       "      <td>6</td>\n",
       "      <td>Fried chicken from where?</td>\n",
       "      <td>fried chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21980</th>\n",
       "      <td>3</td>\n",
       "      <td>Half day respite from parenting on this long P...</td>\n",
       "      <td>half day respite parenting long ph weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21544</th>\n",
       "      <td>1</td>\n",
       "      <td>and yet the birthrates are falling?</td>\n",
       "      <td>yet birthrate falling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26805</th>\n",
       "      <td>7</td>\n",
       "      <td>Almost 60 percent boostered, yet it's 5 people...</td>\n",
       "      <td>almost percent boostered yet people almost per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17704</th>\n",
       "      <td>7</td>\n",
       "      <td>Down for me in bukit panjang. Phone under circ...</td>\n",
       "      <td>bukit panjang phone circle life also intermittent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24247</th>\n",
       "      <td>8</td>\n",
       "      <td>Surely, Anthony Lim Thiam Poh is trolling and ...</td>\n",
       "      <td>surely anthony lim thiam poh trolling first ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>1</td>\n",
       "      <td>Then bank should have let them suck it up</td>\n",
       "      <td>bank let suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23070</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes, moving in the right direction. The great ...</td>\n",
       "      <td>yes moving right direction great test cny peri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18295</th>\n",
       "      <td>7</td>\n",
       "      <td>you can sign up to be a civilian call-taker fo...</td>\n",
       "      <td>sign civilian call taker scdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33808</th>\n",
       "      <td>1</td>\n",
       "      <td>Sigma 男子</td>\n",
       "      <td>sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26067</th>\n",
       "      <td>5</td>\n",
       "      <td>Military driving time, had my boots stuck betw...</td>\n",
       "      <td>military driving time boot stuck pedal shitty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17713</th>\n",
       "      <td>1</td>\n",
       "      <td>Yishun back up</td>\n",
       "      <td>yishun back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18033</th>\n",
       "      <td>4</td>\n",
       "      <td>quite unfair considered that others were cance...</td>\n",
       "      <td>quite unfair considered others cancelled mere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23448</th>\n",
       "      <td>3</td>\n",
       "      <td>Your degree is out of date within 5 years. Aft...</td>\n",
       "      <td>degree date within year year everyone look job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28435</th>\n",
       "      <td>1</td>\n",
       "      <td>Lmao I was just trying to push that the 5k++ c...</td>\n",
       "      <td>lmao trying push k case minor thing big deal s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30253</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes! That shall be me one day!</td>\n",
       "      <td>yes shall one day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37858</th>\n",
       "      <td>1</td>\n",
       "      <td>i like your thinking. \\n\\nif there a few defec...</td>\n",
       "      <td>like thinking defect system entire system useless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32401</th>\n",
       "      <td>1</td>\n",
       "      <td>Where is greener pastures for you?</td>\n",
       "      <td>greener pasture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11667</th>\n",
       "      <td>6</td>\n",
       "      <td>I carrot about you! Hehe it’s a carrot cake &gt;&lt;</td>\n",
       "      <td>carrot hehe carrot cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29771</th>\n",
       "      <td>1</td>\n",
       "      <td>About once a week.</td>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25566</th>\n",
       "      <td>5</td>\n",
       "      <td>How dare you even raise such a question. We ha...</td>\n",
       "      <td>dare even raise question ownself checked ownse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24427</th>\n",
       "      <td>1</td>\n",
       "      <td>Insurance agent = SUSSY BAKA</td>\n",
       "      <td>insurance agent sussy baka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36171</th>\n",
       "      <td>3</td>\n",
       "      <td>Chao turtle. My brother is class monitor so he...</td>\n",
       "      <td>chao turtle brother class monitor accompany cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20609</th>\n",
       "      <td>3</td>\n",
       "      <td>Not everybody can be good at computing. Lower ...</td>\n",
       "      <td>everybody good computing lower rank paid like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13056</th>\n",
       "      <td>6</td>\n",
       "      <td>Technically the kind of curry served at buffet...</td>\n",
       "      <td>technically kind curry served buffet considere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>1</td>\n",
       "      <td>Relationship is a social construct</td>\n",
       "      <td>relationship social construct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29102</th>\n",
       "      <td>1</td>\n",
       "      <td>Has everyone forgotten SERS isn’t guaranteed? ...</td>\n",
       "      <td>everyone forgotten sers guaranteed buyer got i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1</td>\n",
       "      <td>I think homosexuality will always be controver...</td>\n",
       "      <td>think homosexuality always controversial point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19494</th>\n",
       "      <td>3</td>\n",
       "      <td>And yup I agree actually, if I’m the other par...</td>\n",
       "      <td>yup agree actually party would want get closur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23310</th>\n",
       "      <td>3</td>\n",
       "      <td>Vaccination means 100% immunity? What are you ...</td>\n",
       "      <td>vaccination mean immunity smoking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>1</td>\n",
       "      <td>Lucky never caught in army camp. Lol!</td>\n",
       "      <td>lucky never caught army camp lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33728</th>\n",
       "      <td>3</td>\n",
       "      <td>What about ciders? Can consider those bath bom...</td>\n",
       "      <td>cider consider bath bomb lush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20455</th>\n",
       "      <td>1</td>\n",
       "      <td>Uhh so the defence is that he is really a good...</td>\n",
       "      <td>uhh defence really good person everyone vouch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18644</th>\n",
       "      <td>1</td>\n",
       "      <td>Heng got Reddit. In SHN I thought my home wifi...</td>\n",
       "      <td>heng got reddit shn thought home wifi issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29281</th>\n",
       "      <td>5</td>\n",
       "      <td>It's not that, is that people is not naive eno...</td>\n",
       "      <td>people naive enough buy cheap bullcrap show pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>4</td>\n",
       "      <td>Pick up trash at changi beach, feed the stray ...</td>\n",
       "      <td>pick trash changi beach feed stray cat block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31215</th>\n",
       "      <td>3</td>\n",
       "      <td>I don't see this as hardworking but someone wh...</td>\n",
       "      <td>see hardworking someone manage time properly w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15828</th>\n",
       "      <td>6</td>\n",
       "      <td>A lot. You do deadlifts for strength, not to b...</td>\n",
       "      <td>lot deadlifts strength burn calorie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah... That's just cringe.</td>\n",
       "      <td>yeah cringe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25165</th>\n",
       "      <td>1</td>\n",
       "      <td>Seems like it!</td>\n",
       "      <td>seems like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34656</th>\n",
       "      <td>3</td>\n",
       "      <td>&gt; There shouldn't be Law and Order in the firs...</td>\n",
       "      <td>law order first place regardless whatever moti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17505</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, wasn't critiquing you, more the excuse t...</td>\n",
       "      <td>yeah critiquing excuse inevitably given frustr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30737</th>\n",
       "      <td>7</td>\n",
       "      <td>My mum went for annual body checkup and found ...</td>\n",
       "      <td>mum went annual body checkup found trace blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>3</td>\n",
       "      <td>Smash, guy roll ankle...\\n\\n*so, u have health...</td>\n",
       "      <td>smash guy roll ankle u health insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23212</th>\n",
       "      <td>6</td>\n",
       "      <td>I fact you can say the situation in Japan, its...</td>\n",
       "      <td>fact say situation japan bad business owner go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12614</th>\n",
       "      <td>6</td>\n",
       "      <td>When the choice of moving somewhere else isn't...</td>\n",
       "      <td>choice moving somewhere else available much pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17931</th>\n",
       "      <td>1</td>\n",
       "      <td>Tia gong say years ago, his daddy got him a sc...</td>\n",
       "      <td>tia gong say year ago daddy got school transfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>1</td>\n",
       "      <td>Lol! Am I missing out on the best comedy of th...</td>\n",
       "      <td>lol missing best comedy year nah peacemaker st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27591</th>\n",
       "      <td>1</td>\n",
       "      <td>Anyone knows if Liho has student price bubble ...</td>\n",
       "      <td>anyone know liho student price bubble tea weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20427</th>\n",
       "      <td>1</td>\n",
       "      <td>oh i thought the anti great resignation wave a...</td>\n",
       "      <td>oh thought anti great resignation wave article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>1</td>\n",
       "      <td>I just want to highlight that the \"kid\" in que...</td>\n",
       "      <td>want highlight kid question either family bloo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25334</th>\n",
       "      <td>3</td>\n",
       "      <td>S.D.A ? Grab? \\n\\nJokes aside, I believe some ...</td>\n",
       "      <td>grab joke aside believe tweak necessary news s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15169</th>\n",
       "      <td>1</td>\n",
       "      <td>I love them &gt;:)</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26108</th>\n",
       "      <td>3</td>\n",
       "      <td>I am going to be direct and hash and say this ...</td>\n",
       "      <td>going direct hash say family seriously lack ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34896</th>\n",
       "      <td>1</td>\n",
       "      <td>nope. but does someone calling me that deserve...</td>\n",
       "      <td>nope someone calling deserve jail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17746</th>\n",
       "      <td>1</td>\n",
       "      <td>apologise for any “convenience”</td>\n",
       "      <td>apologise convenience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27386</th>\n",
       "      <td>7</td>\n",
       "      <td>Not a doctor but I’m a frontliner working unde...</td>\n",
       "      <td>doctor frontliner working singhealth also thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12458</th>\n",
       "      <td>1</td>\n",
       "      <td>Chad Forest Elderly Man vs Virgin OCS Cadets</td>\n",
       "      <td>chad forest elderly man v virgin ocs cadet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37843</th>\n",
       "      <td>3</td>\n",
       "      <td>necessary lah. need to catch criminals</td>\n",
       "      <td>necessary lah need catch criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>1</td>\n",
       "      <td>About 4 hours 45 minutes? Haha. I did it in th...</td>\n",
       "      <td>hour minute haha evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>4</td>\n",
       "      <td>How much clean water have you used so far to c...</td>\n",
       "      <td>much clean water used far clean trash throwing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20718</th>\n",
       "      <td>4</td>\n",
       "      <td>Who's gonna heal the devide of the charge sheet?</td>\n",
       "      <td>gon na heal devide charge sheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>5</td>\n",
       "      <td>As someone who worked in Dairy Farm (Giant/Col...</td>\n",
       "      <td>someone worked dairy farm giant cold storage p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26695</th>\n",
       "      <td>3</td>\n",
       "      <td>&gt;\\tGrassroot advisers are appointed by PA, whi...</td>\n",
       "      <td>grassroot adviser appointed pa statutory board...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>1</td>\n",
       "      <td>Same here.\\n\\nWe went to watch just to see how...</td>\n",
       "      <td>went watch see accurate melodrama fine highlig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17716</th>\n",
       "      <td>1</td>\n",
       "      <td>Punggol just down like 5 mins ago; do not know...</td>\n",
       "      <td>punggol like min ago know happened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32531</th>\n",
       "      <td>3</td>\n",
       "      <td>You do realize that it has cost in local jobs?...</td>\n",
       "      <td>realize cost local job sometimes one ep mean w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20103</th>\n",
       "      <td>1</td>\n",
       "      <td>So what's the recovery gonna be like? Just sta...</td>\n",
       "      <td>recovery gon na like stay home special medication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36732</th>\n",
       "      <td>1</td>\n",
       "      <td>My passion is money. Payments, fintech, invest...</td>\n",
       "      <td>passion money payment fintech investing anythi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29587</th>\n",
       "      <td>1</td>\n",
       "      <td>Just for fun\\nI won't start the convo\\nMala\\nB...</td>\n",
       "      <td>fun start convo mala bbt friend made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28621</th>\n",
       "      <td>7</td>\n",
       "      <td>Careful - dissent against the rules means you'...</td>\n",
       "      <td>careful dissent rule mean grandma killer someo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic                                               text                                          cleantext\n",
       "3159       5  Thanks for the info. Yes I think I probably do...  thanks info yes think probably use bag time ti...\n",
       "9794       7  Condoms are pretty useful against STDs, which ...  condom pretty useful std appreciate gon na pre...\n",
       "3726       1  What you don't like recycled plots, lifeless c...  like recycled plot lifeless character dialogue...\n",
       "8731       7  It's <20 in icu, 90+ is needing oxygen support...             icu needing oxygen support nasal prong\n",
       "31844      1              Never mind then, I guess I was wrong!                             never mind guess wrong\n",
       "12449      1  Complaint what? He got bigger space than most ...             complaint got bigger space u rent free\n",
       "25355      1  Trickle down is an urban myth. Gaslighting, re...              trickle urban myth gaslighting really\n",
       "9103       6          They are already milking in SGCovidLaKopi                      already milking sgcovidlakopi\n",
       "7684       1  The market can bear the prices they ask, eithe...  market bear price ask either actual quality ma...\n",
       "24583      1  how to count my caloriesss when my mom is such...                   count calorie mom good cook lmao\n",
       "7793       1                       If ART negative, pretty safe                           art negative pretty safe\n",
       "25259     10  tennis1shoe that bastard stole my girl pingpon...       tennis shoe bastard stole girl pingpong shoe\n",
       "25934      1  I want to know what you have been smoking… so ...                         want know smoking try jail\n",
       "10141      5               one of the good result from lockdown                           one good result lockdown\n",
       "39111      3  If this were Soviet Russia, they would have fo...  soviet russia would found way operate liberal ...\n",
       "20132      3  I saw some tiktok video of this lab worker who...  saw tiktok video lab worker antibody test jab ...\n",
       "38113      1     Should have said that it was a workplace event                               said workplace event\n",
       "18374      5  I heard from somewhere that this is a sign of ...  heard somewhere sign anti social lonely people...\n",
       "36924      1                                             \\\\[T]/                                                NaN\n",
       "7117       5  They put down a 70% deposit with the ID. Yikes...                 put deposit id yikes huge red flag\n",
       "38254      1              So that I can collect garbage like u?                             collect garbage like u\n",
       "1764       5  Any good spots to work from in sg? Staying at ...            good spot work sg staying home day sian\n",
       "24013      1            We can be anything we wish to be online                               anything wish online\n",
       "6839       1  >excessive excellent alternates\\n\\nThesaurus w...  excessive excellent alternate thesaurus workin...\n",
       "19737      3  This doesn't solve the problem\\n\\nIf you read ...  solve problem read ocbc incident part issue du...\n",
       "29666      1                wait till you learn what NTUC meant                         wait till learn ntuc meant\n",
       "20728      5                 Pretty nicely endowed for an asian                        pretty nicely endowed asian\n",
       "35219      5  Pretty much impossible  \\n\\nIf you're still yo...  pretty much impossible still young need take a...\n",
       "24709      7  You are not responsible his mental health.\\n\\n...  responsible mental health made clear reciproca...\n",
       "17037      6                          Fried chicken from where?                                      fried chicken\n",
       "21980      3  Half day respite from parenting on this long P...         half day respite parenting long ph weekend\n",
       "21544      1                and yet the birthrates are falling?                              yet birthrate falling\n",
       "26805      7  Almost 60 percent boostered, yet it's 5 people...  almost percent boostered yet people almost per...\n",
       "17704      7  Down for me in bukit panjang. Phone under circ...  bukit panjang phone circle life also intermittent\n",
       "24247      8  Surely, Anthony Lim Thiam Poh is trolling and ...  surely anthony lim thiam poh trolling first ch...\n",
       "5872       1          Then bank should have let them suck it up                                      bank let suck\n",
       "23070      5  Yes, moving in the right direction. The great ...  yes moving right direction great test cny peri...\n",
       "18295      7  you can sign up to be a civilian call-taker fo...                      sign civilian call taker scdf\n",
       "33808      1                                           Sigma 男子                                              sigma\n",
       "26067      5  Military driving time, had my boots stuck betw...  military driving time boot stuck pedal shitty ...\n",
       "17713      1                                     Yishun back up                                        yishun back\n",
       "18033      4  quite unfair considered that others were cance...  quite unfair considered others cancelled mere ...\n",
       "23448      3  Your degree is out of date within 5 years. Aft...  degree date within year year everyone look job...\n",
       "28435      1  Lmao I was just trying to push that the 5k++ c...  lmao trying push k case minor thing big deal s...\n",
       "30253      5                     Yes! That shall be me one day!                                  yes shall one day\n",
       "37858      1  i like your thinking. \\n\\nif there a few defec...  like thinking defect system entire system useless\n",
       "32401      1                 Where is greener pastures for you?                                    greener pasture\n",
       "11667      6     I carrot about you! Hehe it’s a carrot cake ><                            carrot hehe carrot cake\n",
       "29771      1                                 About once a week.                                               week\n",
       "25566      5  How dare you even raise such a question. We ha...  dare even raise question ownself checked ownse...\n",
       "24427      1                       Insurance agent = SUSSY BAKA                         insurance agent sussy baka\n",
       "36171      3  Chao turtle. My brother is class monitor so he...  chao turtle brother class monitor accompany cl...\n",
       "20609      3  Not everybody can be good at computing. Lower ...  everybody good computing lower rank paid like ...\n",
       "13056      6  Technically the kind of curry served at buffet...  technically kind curry served buffet considere...\n",
       "2297       1                 Relationship is a social construct                      relationship social construct\n",
       "29102      1  Has everyone forgotten SERS isn’t guaranteed? ...  everyone forgotten sers guaranteed buyer got i...\n",
       "476        1  I think homosexuality will always be controver...  think homosexuality always controversial point...\n",
       "19494      3  And yup I agree actually, if I’m the other par...  yup agree actually party would want get closur...\n",
       "23310      3  Vaccination means 100% immunity? What are you ...                  vaccination mean immunity smoking\n",
       "701        1              Lucky never caught in army camp. Lol!                   lucky never caught army camp lol\n",
       "33728      3  What about ciders? Can consider those bath bom...                      cider consider bath bomb lush\n",
       "20455      1  Uhh so the defence is that he is really a good...  uhh defence really good person everyone vouch ...\n",
       "18644      1  Heng got Reddit. In SHN I thought my home wifi...        heng got reddit shn thought home wifi issue\n",
       "29281      5  It's not that, is that people is not naive eno...  people naive enough buy cheap bullcrap show pr...\n",
       "506        4  Pick up trash at changi beach, feed the stray ...  pick trash changi beach feed stray cat block b...\n",
       "31215      3  I don't see this as hardworking but someone wh...  see hardworking someone manage time properly w...\n",
       "15828      6  A lot. You do deadlifts for strength, not to b...                lot deadlifts strength burn calorie\n",
       "17373      1                        Yeah... That's just cringe.                                        yeah cringe\n",
       "25165      1                                     Seems like it!                                         seems like\n",
       "34656      3  > There shouldn't be Law and Order in the firs...  law order first place regardless whatever moti...\n",
       "17505      1  Yeah, wasn't critiquing you, more the excuse t...  yeah critiquing excuse inevitably given frustr...\n",
       "30737      7  My mum went for annual body checkup and found ...  mum went annual body checkup found trace blood...\n",
       "8123       3  Smash, guy roll ankle...\\n\\n*so, u have health...            smash guy roll ankle u health insurance\n",
       "23212      6  I fact you can say the situation in Japan, its...  fact say situation japan bad business owner go...\n",
       "12614      6  When the choice of moving somewhere else isn't...  choice moving somewhere else available much pr...\n",
       "17931      1  Tia gong say years ago, his daddy got him a sc...  tia gong say year ago daddy got school transfe...\n",
       "10390      1  Lol! Am I missing out on the best comedy of th...  lol missing best comedy year nah peacemaker st...\n",
       "27591      1  Anyone knows if Liho has student price bubble ...  anyone know liho student price bubble tea weekend\n",
       "20427      1  oh i thought the anti great resignation wave a...  oh thought anti great resignation wave article...\n",
       "5792       1  I just want to highlight that the \"kid\" in que...  want highlight kid question either family bloo...\n",
       "25334      3  S.D.A ? Grab? \\n\\nJokes aside, I believe some ...  grab joke aside believe tweak necessary news s...\n",
       "15169      1                                    I love them >:)                                               love\n",
       "26108      3  I am going to be direct and hash and say this ...  going direct hash say family seriously lack ba...\n",
       "34896      1  nope. but does someone calling me that deserve...                  nope someone calling deserve jail\n",
       "17746      1                    apologise for any “convenience”                              apologise convenience\n",
       "27386      7  Not a doctor but I’m a frontliner working unde...  doctor frontliner working singhealth also thin...\n",
       "12458      1       Chad Forest Elderly Man vs Virgin OCS Cadets         chad forest elderly man v virgin ocs cadet\n",
       "37843      3             necessary lah. need to catch criminals                  necessary lah need catch criminal\n",
       "17196      1  About 4 hours 45 minutes? Haha. I did it in th...                           hour minute haha evening\n",
       "3043       4  How much clean water have you used so far to c...  much clean water used far clean trash throwing...\n",
       "20718      4   Who's gonna heal the devide of the charge sheet?                    gon na heal devide charge sheet\n",
       "4097       5  As someone who worked in Dairy Farm (Giant/Col...  someone worked dairy farm giant cold storage p...\n",
       "26695      3  >\\tGrassroot advisers are appointed by PA, whi...  grassroot adviser appointed pa statutory board...\n",
       "847        1  Same here.\\n\\nWe went to watch just to see how...  went watch see accurate melodrama fine highlig...\n",
       "17716      1  Punggol just down like 5 mins ago; do not know...                 punggol like min ago know happened\n",
       "32531      3  You do realize that it has cost in local jobs?...  realize cost local job sometimes one ep mean w...\n",
       "20103      1  So what's the recovery gonna be like? Just sta...  recovery gon na like stay home special medication\n",
       "36732      1  My passion is money. Payments, fintech, invest...  passion money payment fintech investing anythi...\n",
       "29587      1  Just for fun\\nI won't start the convo\\nMala\\nB...               fun start convo mala bbt friend made\n",
       "28621      7  Careful - dissent against the rules means you'...  careful dissent rule mean grandma killer someo..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rename_topics(text):\n",
    "    if text == 'art':\n",
    "        text = 1\n",
    "    elif text == 'covid19':\n",
    "        text = 2    \n",
    "    elif text == 'education':\n",
    "        text = 3\n",
    "    elif text == 'environment':\n",
    "        text = 4\n",
    "    elif text == 'fashion':\n",
    "        text = 5\n",
    "    elif text == 'food':\n",
    "        text = 6\n",
    "    elif text == 'health':\n",
    "        text = 7\n",
    "    elif text == 'politics':\n",
    "        text = 8\n",
    "    elif text == 'technology':\n",
    "        text = 9\n",
    "    else:\n",
    "        text = 10  \n",
    "    return text\n",
    "\n",
    "sample_reddit_data['topic'] = sample_reddit_data['topic'].apply(rename_topics)\n",
    "sample_reddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.11      0.67      0.19         3\n",
      "           4       0.25      0.33      0.29         3\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.43      0.75      0.55         4\n",
      "           7       0.33      0.33      0.33         9\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       1.00      0.02      0.03        66\n",
      "\n",
      "    accuracy                           0.10       100\n",
      "   macro avg       0.21      0.21      0.14       100\n",
      "weighted avg       0.72      0.10      0.09       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = labelled_reddit_data['topic'].to_list()\n",
    "y_pred = sample_reddit_data['topic'].to_list()\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Zero-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_label_to_df(df):\n",
    "#     df[\"politics\"] = 0\n",
    "#     df[\"business and economy\"] = 0\n",
    "#     df[\"sports\"] = 0\n",
    "#     df[\"arts and entertainment\"] = 0\n",
    "#     df[\"covid19\"] = 0\n",
    "#     df[\"education\"] = 0\n",
    "#     df[\"environment\"] = 0\n",
    "#     df[\"fashion\"] = 0\n",
    "#     df[\"food\"] = 0\n",
    "#     df[\"technology\"] = 0\n",
    "#     df[\"science and medicine\"] = 0\n",
    "#     df[\"law\"] = 0\n",
    "#     df[\"culture\"] = 0\n",
    "#     df[\"religion\"] = 0\n",
    "#     df[\"lifestyle\"] = 0\n",
    "#     df[\"travel\"] = 0\n",
    "#     df[\"healthcare\"] = 0\n",
    "#     df[\"society\"] = 0\n",
    "#     df[\"crime\"] = 0\n",
    "#     df[\"transportation\"] = 0\n",
    "#     df[\"others\"] = 0\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyTopics1(text):\n",
    "    labels = [\"politics\", \"business and economy\", \"sports\", \"arts and entertainment\", \"covid19\", \"education\", \"environment\", \"fashion\", \"food\", \"technology\", \"science and medicine\", \"law\", \"culture\", \"religion\", \"lifestyle\", \"travel\", \"healthcare\", \"society\", \"crime\", \"transportation\", \"others\"]\n",
    "\n",
    "    results_dict = classifier(text, \n",
    "                        labels,\n",
    "                        multi_class=True)\n",
    "\n",
    "    labels = results_dict[\"labels\"]\n",
    "    top_topic = labels[0]\n",
    "    # scores = results_dict[\"scores\"]\n",
    "    \n",
    "    # score_dict = {}\n",
    "    # for i in range(len(labels)):\n",
    "    #     score_dict[labels[i]] = scores[i]\n",
    "\n",
    "    return top_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyTopics2(text):\n",
    "    labels = [\"politics\", \"business and economy\", \"sports\", \"arts and entertainment\", \"covid19\", \"education\", \"environment\", \"fashion\", \"food\", \"technology\", \"science and medicine\", \"law\", \"culture\", \"religion\", \"lifestyle\", \"travel\", \"healthcare\", \"society\", \"crime\", \"transportation\", \"others\"]\n",
    "\n",
    "    results_dict = classifier(text, \n",
    "                        labels,\n",
    "                        multi_class=True)\n",
    "\n",
    "    labels = results_dict[\"labels\"]\n",
    "    top_topic = [labels[0],labels[1]]\n",
    "\n",
    "    return top_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['environment',\n",
       " 'food',\n",
       " 'covid19',\n",
       " 'crime',\n",
       " 'culture',\n",
       " 'society',\n",
       " 'healthcare',\n",
       " 'law',\n",
       " 'lifestyle',\n",
       " 'science and medicine',\n",
       " 'business and economy',\n",
       " 'technology',\n",
       " 'education',\n",
       " 'travel',\n",
       " 'others',\n",
       " 'arts and entertainment',\n",
       " 'fashion',\n",
       " 'transportation',\n",
       " 'politics',\n",
       " 'sports',\n",
       " 'religion']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I was eating at the hawker center last Sunday when a random person decided to just sit opposite me and started eating without even asking if I'm okay with that. Since we are eating, we both were unmasked. We were in close contact for more than 10 mins. There were no other seats so I couldn't move away. There were no other instances where I could have gotten it as that was the only time I was unmasked while being in close proximity with a stranger.The very rule that was supposed to stop the spread was what spread it to me. If the smm didn't exist, there would have been more tables available and that stranger would have found a table elsewhere.TLDR: Random stranger sat opposite me while eating at hawker center cos of lack of tables due to SMM. Tested positive and after looking back, that incident was most probably where I got the infection.\"\n",
    "text\n",
    "\n",
    "topics = classifyTopics(text)\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Facebook data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>topic_labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-19T12:46:52+0000</th>\n",
       "      <td>7 alliances are looking to gradually resume Si...</td>\n",
       "      <td>7 alliances are looking to gradually resume Si...</td>\n",
       "      <td>business and economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    message  \\\n",
       "created_time                                                                  \n",
       "2020-11-19T12:46:52+0000  7 alliances are looking to gradually resume Si...   \n",
       "\n",
       "                                                                  cleantext  \\\n",
       "created_time                                                                  \n",
       "2020-11-19T12:46:52+0000  7 alliances are looking to gradually resume Si...   \n",
       "\n",
       "                                  topic_labels  \n",
       "created_time                                    \n",
       "2020-11-19T12:46:52+0000  business and economy  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 200 posts for evaluation\n",
    "# fb_posts_df_sample = fb_posts_df.sample(200)\n",
    "# fb_posts_df_sample.to_csv(\"fb_sample.csv\")\n",
    "\n",
    "fb_sample = pd.read_csv(\"fb_sample.csv\", index_col=0)\n",
    "\n",
    "# Add each topic as a column to the sampled data\n",
    "# add_label_to_df(fb_sample)\n",
    "\n",
    "# Apply simple preprocessing to remove html/markdown elements and links\n",
    "fb_sample[\"cleantext\"] = fb_sample[\"message\"].apply(preprocessing)\n",
    "\n",
    "# Run through topic classifier to return list of topics in order of contribution\n",
    "fb_sample[\"topic_labels\"] = fb_sample[\"cleantext\"].apply(classifyTopics1)\n",
    "fb_sample.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Class Classifier\n",
    "\n",
    "Each post can only be classified into one topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding on topic labels for each post\n",
    "fb_sample_single_class = fb_sample.copy()\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(fb_sample_single_class[\"topic_labels\"])\n",
    "\n",
    "labelencoder_mapping = dict(zip(labelencoder.classes_, labelencoder.transform(labelencoder.classes_)))\n",
    "labelencoder_mapping\n",
    "\n",
    "labels = list(labelencoder_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>topic_labels</th>\n",
       "      <th>encoded_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-19T12:46:52+0000</th>\n",
       "      <td>7 alliances are looking to gradually resume Si...</td>\n",
       "      <td>7 alliances are looking to gradually resume Si...</td>\n",
       "      <td>business and economy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    message  \\\n",
       "created_time                                                                  \n",
       "2020-11-19T12:46:52+0000  7 alliances are looking to gradually resume Si...   \n",
       "\n",
       "                                                                  cleantext  \\\n",
       "created_time                                                                  \n",
       "2020-11-19T12:46:52+0000  7 alliances are looking to gradually resume Si...   \n",
       "\n",
       "                                  topic_labels  encoded_topic  \n",
       "created_time                                                   \n",
       "2020-11-19T12:46:52+0000  business and economy              1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_sample_single_class[\"encoded_topic\"] = labelencoder.transform(fb_sample_single_class[\"topic_labels\"])\n",
    "fb_sample_single_class.head(1)\n",
    "\n",
    "# for index, row in fb_sample_single_class.iterrows():\n",
    "#     label1 = row[\"topic_labels\"][0]\n",
    "\n",
    "#     fb_sample_single_class.at[index, label1] = 1\n",
    "\n",
    "# fb_sample_single_class.iloc[:, 1:-2].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>topic</th>\n",
       "      <th>encoded_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-19T12:46:52+0000</th>\n",
       "      <td>7 alliances are looking to gradually resume Si...</td>\n",
       "      <td>business and economy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    message  \\\n",
       "created_time                                                                  \n",
       "2020-11-19T12:46:52+0000  7 alliances are looking to gradually resume Si...   \n",
       "\n",
       "                                         topic  encoded_topic  \n",
       "created_time                                                   \n",
       "2020-11-19T12:46:52+0000  business and economy              1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_class_labelled = pd.read_csv(\"fb_sample_zero_shot_single_class.csv\", index_col=0)\n",
    "single_class_labelled.head(1)\n",
    "\n",
    "single_class_labelled = single_class_labelled[[\"message\", \"topic\"]]\n",
    "single_class_labelled[\"encoded_topic\"] = labelencoder.transform(single_class_labelled[\"topic\"])\n",
    "single_class_labelled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "arts and entertainment       0.25      0.40      0.31         5\n",
      "  business and economy       0.36      0.44      0.40         9\n",
      "               covid19       0.44      0.38      0.41        21\n",
      "                 crime       0.39      0.58      0.47        12\n",
      "               culture       0.17      0.50      0.25         4\n",
      "             education       0.33      0.75      0.46         4\n",
      "           environment       0.33      0.33      0.33         6\n",
      "               fashion       1.00      1.00      1.00         1\n",
      "                  food       0.25      1.00      0.40         2\n",
      "            healthcare       0.38      0.50      0.43         6\n",
      "                   law       0.00      0.00      0.00         4\n",
      "             lifestyle       0.00      0.00      0.00         8\n",
      "                others       0.35      0.09      0.15        74\n",
      "              politics       0.64      0.54      0.58        13\n",
      "  science and medicine       1.00      0.33      0.50         3\n",
      "               society       0.20      0.15      0.17        13\n",
      "                sports       0.50      1.00      0.67         4\n",
      "            technology       0.31      1.00      0.47         4\n",
      "        transportation       0.22      1.00      0.36         4\n",
      "                travel       0.14      0.67      0.24         3\n",
      "\n",
      "              accuracy                           0.33       200\n",
      "             macro avg       0.36      0.53      0.38       200\n",
      "          weighted avg       0.35      0.33      0.29       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = fb_sample_single_class.iloc[:, -1:].values.flatten()\n",
    "y_true = single_class_labelled.iloc[:, -1:].values.flatten()\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=labels)) #classification report from sklearn\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-Class Classifier\n",
    "\n",
    "Each post can be classified into up to 2 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>topic_labels</th>\n",
       "      <th>multi_topic_labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-19T12:46:52+0000</th>\n",
       "      <td>7 alliances are looking to gradually resume Si...</td>\n",
       "      <td>7 alliances are looking to gradually resume Si...</td>\n",
       "      <td>business and economy</td>\n",
       "      <td>[business and economy, technology]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    message  \\\n",
       "created_time                                                                  \n",
       "2020-11-19T12:46:52+0000  7 alliances are looking to gradually resume Si...   \n",
       "\n",
       "                                                                  cleantext  \\\n",
       "created_time                                                                  \n",
       "2020-11-19T12:46:52+0000  7 alliances are looking to gradually resume Si...   \n",
       "\n",
       "                                  topic_labels  \\\n",
       "created_time                                     \n",
       "2020-11-19T12:46:52+0000  business and economy   \n",
       "\n",
       "                                          multi_topic_labels  \n",
       "created_time                                                  \n",
       "2020-11-19T12:46:52+0000  [business and economy, technology]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run through topic classifier to return list of topics in order of contribution\n",
    "fb_sample[\"multi_topic_labels\"] = fb_sample[\"cleantext\"].apply(classifyTopics2)\n",
    "fb_sample.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7 alliances are looking to gradually resume Singapore's Mice sector in the aftermath of the Covid-19 pandemic, grow e-commerce and raise productivity through robotics, among other things.</th>\n",
       "      <td>business and economy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[business and economy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  topic1  \\\n",
       "message                                                                    \n",
       "7 alliances are looking to gradually resume Sin...  business and economy   \n",
       "\n",
       "                                                   topic2  \\\n",
       "message                                                     \n",
       "7 alliances are looking to gradually resume Sin...    NaN   \n",
       "\n",
       "                                                                    topics  \n",
       "message                                                                     \n",
       "7 alliances are looking to gradually resume Sin...  [business and economy]  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labelled\n",
    "fb_sample_multilabel = pd.read_csv(\"fb_sample_zero_shot_labelled.csv\", index_col=0)\n",
    "\n",
    "fb_sample_multilabel['topics'] = fb_sample_multilabel[['topic1', 'topic2']].values.tolist()\n",
    "fb_sample_multilabel['topics'] = fb_sample_multilabel[\"topics\"].apply(lambda x:[topic for topic in x if not pd.isnull(topic)])\n",
    "fb_sample_multilabel.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer(classes=labels)\n",
    "multilabel_binarizer.fit(fb_sample_multilabel[\"topics\"])\n",
    "\n",
    "y_true2 = multilabel_binarizer.transform(fb_sample_multilabel[\"topics\"])\n",
    "y_pred2 = multilabel_binarizer.transform(fb_sample[\"multi_topic_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "arts and entertainment       0.27      0.80      0.40         5\n",
      "  business and economy       0.30      0.40      0.34        15\n",
      "               covid19       0.22      0.43      0.29        23\n",
      "                 crime       0.34      0.71      0.47        14\n",
      "               culture       0.10      0.50      0.16         6\n",
      "             education       0.44      0.80      0.57         5\n",
      "           environment       0.18      0.57      0.28         7\n",
      "               fashion       1.00      1.00      1.00         1\n",
      "                  food       0.33      0.80      0.47         5\n",
      "            healthcare       0.29      0.57      0.38         7\n",
      "                   law       0.43      0.30      0.35        10\n",
      "             lifestyle       0.11      0.07      0.08        15\n",
      "                others       0.29      0.19      0.23        78\n",
      "              politics       0.50      0.50      0.50        16\n",
      "  science and medicine       0.40      0.67      0.50         3\n",
      "               society       0.24      0.26      0.25        19\n",
      "                sports       0.50      1.00      0.67         4\n",
      "            technology       0.17      0.80      0.29         5\n",
      "        transportation       0.13      1.00      0.24         4\n",
      "                travel       0.10      1.00      0.18         3\n",
      "\n",
      "             micro avg       0.25      0.40      0.31       245\n",
      "             macro avg       0.32      0.62      0.38       245\n",
      "          weighted avg       0.29      0.40      0.31       245\n",
      "           samples avg       0.25      0.41      0.30       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true2, y_pred2, target_names=labels)) #classification report from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Simple ML Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using CNA Article Text as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(text):\n",
    "    title = text.split(\"</h1>, \\'text\\': \\'\")[0]\n",
    "    title = title.replace(\"{\\'title\\': <h1 class=\\\"h1 h1--page-title\\\">\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/lingjia/SMT_Project_Experience/app/ml/data/Trending Topics/cna_text\"\n",
    "\n",
    "topic_df = []\n",
    "for file in os.listdir(PATH):\n",
    "    topic = file.split(\"_\")[0]\n",
    "    df_training = pd.DataFrame()\n",
    "    df= pd.read_csv(os.path.join(PATH, file), index_col=0)\n",
    "    df_training[\"title\"] = df[\"data\"].apply(get_title)\n",
    "    df_training[\"topic\"] = topic\n",
    "\n",
    "    topic_df.append(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hong Kong food supplies may be disrupted...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighing instruments at 2 FairPrice outl...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Mislabelling' of salmon weight at FairP...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commentary: Losing weight after festive ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDB, SCDF add a dash of humour to New Yo...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5 ways the Esplanade has made an impact ...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Dying indigenous cultures? These young M...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Cambodian nature and childhood inspire I...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Typewriting the future: A dying art in a...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>ASIA'S FUTURE CITIES: Manila residents f...</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3490 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title topic\n",
       "0          Hong Kong food supplies may be disrupted...  food\n",
       "1          Weighing instruments at 2 FairPrice outl...  food\n",
       "2          'Mislabelling' of salmon weight at FairP...  food\n",
       "3          Commentary: Losing weight after festive ...  food\n",
       "4          HDB, SCDF add a dash of humour to New Yo...  food\n",
       "..                                                 ...   ...\n",
       "106        5 ways the Esplanade has made an impact ...   art\n",
       "107        Dying indigenous cultures? These young M...   art\n",
       "108        Cambodian nature and childhood inspire I...   art\n",
       "109        Typewriting the future: A dying art in a...   art\n",
       "110        ASIA'S FUTURE CITIES: Manila residents f...   art\n",
       "\n",
       "[3490 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.concat(topic_df)\n",
    "training_data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f292722d6d50c2426abae6fd15a85386b49c5393ec98f1c35f79e4e4dd7448b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
