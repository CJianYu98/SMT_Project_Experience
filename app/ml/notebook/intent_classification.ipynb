{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://smt483:SMT483tls@10.0.104.84:27017/smt483\")\n",
    "\n",
    "import string\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = text.encode('ascii', errors=\"ignore\").decode()\n",
    "    text = \"\".join([ch for ch in text if ch in string.printable])\n",
    "    text = text.replace(\"\\n\", \"\").replace(\"\\nl\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\\\\",\"\").replace(\"--\", \"\").replace(\"|:-\", \"\").replace(\"|\", \" \").replace(\"#\", \"\").replace(\"&x200B;\", \"\").replace(\"Read the full story here:\", \"\").replace(\"More short stories here:\", \"\").replace(\"Full story here:\", \"\").replace(\"Full story and details here:\", \"\").replace(\"More details here:\", \"\").replace(\"More short stories here:\", \"\")\n",
    "\n",
    "    remove_reader_contribution_tags = re.sub('<Reader Contribution\\W?[\\w*\\s*]*\\>', '', text)\n",
    "    remove_credits_tags = re.sub('<Credits:\\W?[\\w*\\s*]*\\>', '', remove_reader_contribution_tags)\n",
    "    markdown_removed = re.sub('\\*+\\W+', '', remove_credits_tags)\n",
    "    link_removed = re.sub('\\(?https?://[A-Za-z0-9./_\\-!@#$%^&*+={}[\\]<>:;?]*\\)?', '', markdown_removed)\n",
    "\n",
    "    return link_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Intent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bfbf7156924e9bbd0e7b94a41361c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38deedbe310440f69652f4aaf9284447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b52d9bda904ad5a30c3048de372c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87dd3802ae542ccab0421d5d8413472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyIntent(text):\n",
    "    labels = [\"suggestion\", \"complaint\", \"educational\", \"question\", \"remark\"]\n",
    "\n",
    "    results_dict = classifier(text, \n",
    "                    labels)\n",
    "\n",
    "    labels = results_dict[\"labels\"]\n",
    "    intent = labels[0]\n",
    "    # scores = results_dict[\"scores\"]\n",
    "    \n",
    "    # score_dict = {}\n",
    "    # for i in range(len(labels)):\n",
    "    #     score_dict[labels[i]] = scores[i]\n",
    "\n",
    "    return intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complaint'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I was eating at the hawker center last Sunday when a random person decided to just sit opposite me and started eating without even asking if I'm okay with that. Since we are eating, we both were unmasked. We were in close contact for more than 10 mins. There were no other seats so I couldn't move away. There were no other instances where I could have gotten it as that was the only time I was unmasked while being in close proximity with a stranger.The very rule that was supposed to stop the spread was what spread it to me. If the smm didn't exist, there would have been more tables available and that stranger would have found a table elsewhere.TLDR: Random stranger sat opposite me while eating at hawker center cos of lack of tables due to SMM. Tested positive and after looking back, that incident was most probably where I got the infection.\"\n",
    "\n",
    "intent = classifyIntent(text)\n",
    "intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who thinks that McDonalds have been giving sma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  Who thinks that McDonalds have been giving sma..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_posts = client.smt483.fb_posts\n",
    "fb_posts_df = pd.DataFrame(list(fb_posts.find()))\n",
    "fb_posts_df = fb_posts_df[[\"message\"]]\n",
    "\n",
    "fb_posts_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1146086/3309877487.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fb_posts_df_sample[\"cleantext\"] = fb_posts_df_sample[\"message\"].apply(preprocessing)\n"
     ]
    }
   ],
   "source": [
    "fb_posts_df_sample = fb_posts_df[:500]\n",
    "\n",
    "fb_posts_df_sample[\"cleantext\"] = fb_posts_df_sample[\"message\"].apply(preprocessing)\n",
    "fb_posts_df_sample[\"intent_label\"] = fb_posts_df_sample[\"cleantext\"].apply(classifyIntent)\n",
    "\n",
    "fb_posts_df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_labelled = pd.read_csv(\"\")\n",
    "\n",
    "data_labelled[\"cleantext\"] = data_labelled[\"message\"].apply(preprocessing)\n",
    "data_labelled[\"intent_label\"] = data_labelled[\"cleantext\"].apply(classifyIntent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(df, true_label_col, pred_label_col):\n",
    "    labelencoder = LabelEncoder()\n",
    "    labelencoder.fit(df[true_label_col])\n",
    "\n",
    "    labelencoder_mapping = dict(zip(labelencoder.classes_, labelencoder.transform(labelencoder.classes_)))\n",
    "    labels = list(labelencoder_mapping.keys())\n",
    "\n",
    "    df[\"true_encoded_topic\"] = labelencoder.transform(df[true_label_col])\n",
    "    df[\"pred_encoded_topic\"] = labelencoder.transform(df[pred_label_col])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation(df, true_label_col, pred_label_col, label_cat):\n",
    "    y_pred = df[pred_label_col].values.flatten()\n",
    "    y_true = df[true_label_col].values.flatten()\n",
    "\n",
    "    return classification_report(y_true, y_pred, target_names=label_cat))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
